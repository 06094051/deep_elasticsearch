# 问题1：ROOT用户启动ES后出现Too many open files异常
https://elasticsearch.cn/question/4702

1）在一个单机环境通过root用户启动ES，共有690个分片，却出现Too many open files异常，部分分片无法启动，系统的句柄数配置为65534，感觉应该是够了，却不知为何出现这种异常，可能跟启动用户有关。

回复：这个原因有很多，首先你要确认的是 Elasticsearch 具体的可用句柄数到底是多少，Elasticsearch 有 API 可以看的。

http://localhost:9200/_nodes/stats?pretty：

在 process 节点下面找到：


```
"process" : {
"timestamp" : 1530755737626,
"open_file_descriptors" : 620,
"max_file_descriptors" : 10240,
```

可以看到当前打开的和最大的设置。

2）一般来说一台机器上65534个文件句柄对于ES来说足够用了，除非很夸张了的在单机上存储了大量的小索引。   另外要确认ES的启动用户，以及改用户的文件句柄书设置的确正确并生效了。 切换到对应的用户下，用ulimit -n 复核一下。

# 2、【存储相关】哪种类型的数据会占用大量terms_memory，有何优化方案？
https://elasticsearch.cn/question/4714

1）集群中有一个索引每天产生2+TB的数据，大约占用掉10G的内存，其中terms_memory占了9G+。mapping中所有string类型的字段使用keyword类型，有一个msg字段较长，将该字段的index设为false之后，内存降到6G+但仍然较高。

我认为的terms_memory是使用倒排索引占用的内存，倒排是在分词之后产生的，keyword类型的不需要分词为什么也会占用terms_memory？是不是因为keyword字段中，整个字段中的内容就是一个term？
在关闭index之后还剩下6G+的terms_memory是哪些功能占用的？

2）据我所知，目前没有api可以查看单个字段的term memory。

3）keyword 不是不分词，是把整个内容作为一个 term 处理，index 设为 false 是不分词，也就意味着不能针对该字段作搜索。
 
如果仅过滤和聚合分析还可以把 norms 设为 false，如果不做聚合分析和排序，那么嗨可以把 doc_value 设为 false
 
 
还有一个设置是 enabled 设置为 false 的话，就只做存储，其他啥都做不了了

# 3、ES的写操作疑问
版本：ES6.x
看了网上的很多说ES插入操作的流程，有如下疑问：
 
当请求要创建Doc的时候，主分片接受请求并转发请求到副本所在的节点的时候，是主分片写成功就返回给客户端成功了还是要等所有的副本分片都成功了才返回给客户端成功，如果是第二个的话 那么有的副本分片所在的节点写失败了或者超时了 这个时候是怎么处理的，有点疑问，请知道的同学说下这个流程。谢谢

https://elasticsearch.cn/question/4764

1）当前版本(ES6.0)里，每个shard都会在master结点里维护一个in-sync group。 每次写操作，都是先发给对应in-sync group里的主片，主片写成功以后，再并发转发给group内其他的副片。 只有全部主和副都写成功了，才会返回给客户端。
 
如果主片写成功了，但某个副片所在结点故障，无法响应或者响应超时， 主分片会向master发送shard failed通知，由master更新in-sync group，将失败的副片从组内剔除出去。 之后，只要是剩余的in-sync shard都写成功了，就会返回给客户端。 默认的集群配置情况下，只要in-sync group里有至少一个shard可用(用来担当主片角色)，写入就可以成功，并返回给客户端。

2）es在新建更新删除的时候都会遵循两个原则 consistency 和 timeout 具体看下文档吧 
https://www.elastic.co/guide/cn/elasticsearch/guide/current/distrib-write.html

# 4、ES 官方文档说可以通过配置文件指定节点的类型。但是没有写怎么在配置文件中写啊？求指教

-Enode.attr.size=big这个值？在配置文件中怎么写具体。

在elasticsearch.yaml里用如下格式写就可以了
node.attr.boxtype: strong
node.attr.group: 10
属性可以有多个。

# 5、一个索引有5亿的数据量，且这个索引有更新操作，请问多少shards合适呢？
https://elasticsearch.cn/article/32

data节点有50台（16C/32G），25shards+25replica这样合理吗？

kennywu76 回复 Todo
1）
如果单次搜索的时延可以满足业务上的要求，可以这么划分。 如果时延过高，可以增加shard数量，代价是每次搜索的并发量增大，带来的额外开销更大，因而集群能支撑的峰值QPS可能会降低。 原则上，在满足搜索时延的前提下，划分尽量少的shard。 

另外有一种场景划分更多的shard是合理的，那就是集群大多数搜索都会用到某个字段做过滤，比如城市id。 这个时候，可以用该字段做为routing_key，将相关联的数据route到某个或某几个(如果用到routing partition)shard。 适当多划分一些shard，可以让单个shard上的数据集较小，搜素速度快，同时因为搜索不会hit所有的shard，规避了划分过多的shard带来的并发过高，以及需要汇总的数据过多引起的性能问题。

# 6、【缓存问题】如果索引频繁更新，缓存会怎么办
如果索引频繁更新，缓存会怎么办？缓存不就会导致搜索结果不对了吗

https://elasticsearch.cn/question/4908

回复：我先假定你谈论的是Query Cache，也就是用来cache无需打分的filter的结果集的。 那么这个cache是智能且准实时的。 也就是说一旦cache第一次建立以后，索引新增的数据，在搜索的时候，会被增量的加入到cache里。  更细节地点讲，这个cache粒度是在segment级别的，增量cache构建，就是针对新增的segment，以及发生过merge的segment。

# 7、"cluster.routing.allocation.disk.watermark.low"参数为什么不能禁止向节点分片分片？
"cluster.routing.allocation.disk.watermark.low"这个参数是当某个节点的磁盘使用量达到设置值后，集群将不再向此节点分配副本分片，注意，不再分配副本分片。所以这个配置项对于主分片是透明的。
所以如果集群中有的数据节点快被写满了，这个值是没有什么作用的。、
我的问题是：ES为什么只能限制副本分片的分配？如果节点被写满，节点会出现故障，集群也会出现故障，为什么不能设置"cluster.routing.allocation.disk.watermark.low"这个参数禁止所有新分配的分片？
 
我的想法是：ES重平衡是按照节点分片数来重平衡的，如果"cluster.routing.allocation.disk.watermark.low"这个值可以禁止所有分片的分配，将势必造成集群节点间分片数的不平等，从而造成持续的“重平衡”，而有些节点又禁止分配分片，这样的话，集群将处于不断启动重平衡的死循环？

https://elasticsearch.cn/question/4911

回复:
low watermark不是对主分片透明，如果你仔细阅读一下文档，这个参数是对“未分配过的"主分片无效，即新创建的索引的场景。 也就是说一个结点的磁盘空间消耗达到low watermark以后，新创建的索引不受限制，依然可以分配到上面。 不能够分配上去的场景主要是以下两个:
集群有结点挂掉或者用户更改了集群的复制片数量， 需要挑选某个结点复制分片的时候
集群触发了rebalance的时候
 
这么设计也是有道理的，low watermark表达的含义是磁盘空间较低，为了保护已有数据的进一步空间消耗（数据的持续写入， merge的临时空间消耗)，禁止有数据的shard向上面分配。 而新创建的索引，一开始是空的，分配上去也无所谓。
 
low watermark是不管磁盘数据结点是否快写满了的，有另外一个参数"cluster.routing.allocation.disk.watermark.high"来处理这种情况。这个阈值触发以后，ES会将该结点上的数据开始往其他结点迁移，该参数对所有shard有效。
 
两个watermark合理配置，可以减少数据迁移的频率，同时保障结点磁盘空间不会过低。
 
最后还有一道防线"cluster.routing.allocation.disk.watermark.flood_stage" ，万一应用写数据太猛，超过预期，磁盘空间降太快，来不及往外迁移，这个阈值触可能被触发。 触发时，ES会将结点上的索引设置为只读, 避免磁盘空间爆掉，影响结点的可用性。

# 8、ES中threadpool的direct类型
在阅读ES2.1源码的过程中发现thread pool的类型有四种
cached,fixed,scaling这三种类型在官网上都能查到，direct是什么类型呢？

https://elasticsearch.cn/question/4927

回复1：参考
https://www.felayman.com/articles/2017/11/10/1510291570687.html

1）direct
此类线程是一种不支持关闭的线程,就意味着一旦使用,则会一直存活下去.

2）fixed
此类线程池拥有固定数量的线程来处理请求，在没有空闲线程时请求将被挂在队列中（可选配）

3）scaling
此类线程池拥有的线程数量是动态的。这个数字介于core和max参数的配置之间变化

回复2：Direct类型表示用当前线程执行提交的任务，并且该线程不能被关闭。我的理解是比较轻量级或者需要单线程执行的任务提交给这个executor。


# 9、Elasticsearch查询时指定分词器
问题描述:
    ES目前使用的是IK分词器,查询时的分词也是IK,但现在想查询走的分词还是ES的 Standard Analyzer
	 es_result = get_es_connect().search(
            index=index,
            doc_type=_type,
            body=dsl,
            timeout=timeout
        )
	使用python语言编码， 这个search有个analyzer参数,指定为standard报错.
请问这个问题是在mapping中指定呢,还是可以在方法中指定，请指点一二？

https://elasticsearch.cn/question/4979

有三种方式可以指定查询分析器:
1）. 在mapping里指定search_analyzer，例如
PUT my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "uid": {
          "type": "keyword"
        },
        "name": {
          "type": "text",
          "analyzer": "english",
          "search_analyzer": "standard"
        }
      }
    }
  }
}
 
2）.使用URL Search的时候，指定analyzer参数 ，文档参考: https://www.elastic.co/guide/e ... .html , 对应的python代码范例: 
>>> es.search(index="my_index", analyzer="standard", q='name:"mark AND johnson"')
要注意的是，这里的analyzer只能和q这个参数搭配使用。 你的代码报错，是因为用的body参数，这个参数是没有analyzer参数搭配的。

3）使用Request Body Search，文档参考: https://www.elastic.co/guide/e ... .html  ,对应的python代码范例:
>>> dsl='{"query": {"match": {"name": {"query": "mark","analyzer": "standard"}}}}'
>>> es.search(index="my_index", body=dsl)
注意这个时候，analyzer是写到dsl里面的match query。

# 10、【复杂聚合，空间换时间】elasticsearch多重聚合、排序、性能？
源自公司 店铺搜索的需求
1、检索字段为 店铺名+商品名
2、店铺下存在商品，商品存在主子商品，也就是需要两层聚合
3、如果只命中商品名，并且命中商品名个数小于4，则该店铺不返回
4、需要支持店铺内商品的销量排序，如果商品名命中了则权重大于销量权重
5、支持店铺层面的分页获取

本人试了父子文档，需要建立两层子文档，使用hasparent查询回店铺效率还好，但是使用haschild查询时，需要查询两层，性能大大降低了，大神们有没有什么好的解决办法

https://elasticsearch.cn/question/4680

medcl回复：追求性能的话，能不用父子查询就别用，都在一个索引文档里面，冗余一点其实也没啥。

# 11、【5.3已经移除】query and fetch 在什么情况下会用到呢
query and fetch和then的区别是前者只需要去每个分片去一次size大小的数据，后者是先fetch文档得分id等元数据信息，然后再取topN。
 
这样看来，前者虽然只有一次rpc，但是一次查询后再coordinate中占用内存很多，分片越大，size增多会有隐患。而后者虽然要走两次rpc，但是第一次获取元数据信息内存占用很少，第二次只需要获取size大小数据即可，感觉还是可以接受的。
 
而且前者返回的是size的N倍（N是分片数），业务上通常都是去多少用多少的，我设置size=10你给我30我会认为查询语句有错误，不希望要多余的数据。后者至少能保证我取多少就要多少。
 
所以不明白前者为什么不在返回之前做一次topN。
 那么query and fetch 在什么场景 下会用到 呢？
https://elasticsearch.cn/question/4740

medcl 回复：
query_and_fetch 主要是用来进行内部优化的，如果你只有一个分片，你完全不需要分两个阶段（记住，你只有一个分片，不用管其他分片的情况），先拿一次分片下的得分信息再拿具体的文档，不如一次性拿回来就好了。
 
所以 query_and_fetch 从来不是直接给用户来使用的，并且在 5.3 版本之后已经移除了这个选项。
你看最新的文档，query_and_fetch 这个参数在 search_type 里面也是没有的。

# 12、【博客】聊聊ELASTICSEARCH的集群状态的管理和维护

https://elasticsearch.cn/article/711

http://vearne.cc/archives/616

# 13、filebeat写入1500w数据到es
手头需求是写入1500W条json数据 每条数据800个字段 10000条json文件数据现在是90M左右，现在复制出100份，用filebeat扫描进es， es配了4台，由于现在手头没物理机资源，只能在4台2g内存的虚拟机... 然后现在的写入速度很堪忧，测了下 平均 0.92m/s 180条/s，这要搞到1500w条太慢了， 不知是虚拟机内存的影响大 还是filebeat写入es没开启bulk写入？还是filebeat本身性能瓶颈

medcl - Elastic 🇨🇳 ！
自己写程序可能还更快点，Filebeat 不是用来批量导入数据的

# 14、es查询结果 保存或者下载
es或者kibana，将查询到的结果，保存到文件或者下载，有类似的接口或者功能吗？
麻烦了解的大神，简单说明一下

kibana 5.5及以上 有report导出功能 https://www.elastic.co/guide/en/kibana/5.5/xpack-reporting.html
其他版本 用es scan scroll 方式自己导出吧

# 15、kibana时区问题
问题概述：
       架构是：filebeat>es>kibana
       需求：使用filebeat模块采集分析nginx，access/error日志
       在采集access日志的时候，没有任何问题，时区、字段等数据都正常，但在采集error日志的时候，发现kibana展示的时间比实际日志时间快8个小时。随后看了下access的日志格式“03/Jul/2018:00:00:01 +0800”后面有个+0800，所以kibana展示的时候是正常的，而error的日志格式为：“2018/06/19 09:10:15”，就导致了kibana展示的时间比实际日志时间快8个小时，因为后面没有时区的参数。请问各位怎么去解决？网上说的修改kibana时区，改了shanghai，重新加索引，依然没有解决。我使用的是filebeat的nginx模块，能不能在不修改日志格式，不动客户端的情况下，解决这个问题？以下是相关截图：
       
https://elasticsearch.cn/question/4754


更改 /usr/share/filebeat/module/nginx/error/ingest/pipeline.json 文件
 
{
    "date": {
      "field": "nginx.error.time",
      "target_field": "@timestamp",
      "formats": ["YYYY/MM/dd H:m:s"],
      "timezone": "Asia/Shanghai"
    }
}

 设置一下timezone就可以了
 
https://www.elastic.co/guide/e ... .html

# 16、ogstash如何判断数据类型
我收到的数据主要是json的，json里面的字段会存在子串，由于历史原因，这些子串有些是json的，有些是个string类型的字符串。如何判断字段类型，然后如果是string类型的就可以用json转化了，如果是json类型的就不需要转换。

如果是 json 类型的，那么你去判断是否存在某个 key 是否存在即可，不存在则为字符串
 
if ![json_str][key_must_exist] {
      # 字符串，做 json 解析
}

# 17、elastic如何删除不需要的字段

方式一：

```
curl -XPOST 'localhost:9200/test/type1/1/_update' -d '{
    "script" : "ctx._source.remove(\"name_of_field\")"
}'
```

方式二：
步骤1：

```
POST _reindex
{
  "source": {
    "index": "old_index"
  },
  "dest": {
    "index": "new_index"
  },
  "script": {
    "inline": """
    if (ctx._type == "bad_type") {
      ctx._source.remove("bad_field");
    }
"""
  }
}
```

步骤2：

```
POST /_aliases
{
  "actions": [
    {
      "add": {
        "index": "new_index",
        "alias": "old_index"
      }
    },
    {
      "remove_index": {
        "index": "old_index"
      }
    }
  ]
}
```

# 18、【少见多怪】es里存在完全相同两条记录
在es里发现存在完全相同的两条记录，_index相同，_type相同，_id也相同，请问这个是什么原因导致的？有人遇到过吗？

可能的bug ：https://github.com/elastic/elasticsearch/issues/31976#issuecomment-404722753

# 19、es索引模板-未知字段怎么设置默认类型

https://elasticsearch.cn/question/4958
dynamic template
你可以参考下官方 filebeat monitor 等里面 的 template，比如下面这个
{
```
"dynamic_templates": [
          {
            "disabled_payload_fields": {
              "match_pattern": "regex",
              "path_match": """result\.(input(\..+)*|(transform(\..+)*)|(actions\.transform(\..+)*))\.payload""",
              "mapping": {
                "type": "object",
                "enabled": false
              }
            }
          }]}
```


关注：铭毅天下公众号！ 更短时间更快习得更多ELK Stack干货！
