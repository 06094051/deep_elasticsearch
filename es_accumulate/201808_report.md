# 1、logstash 数据迁移

大佬们问个问题：使用logstash 将索引数据从６．３　迁移到低版本的５．２，
而高版本的es　使用了search guard　加密，那我应该怎么写logstash 的input（业务场景先不说了.....）
 
帐号　密码　ssl证书啥的在input 应该怎么定义

回复：
直接使用 reindex 不就可以了，
```
POST _reindex
{
  "source": {
    "remote": {
      "host": "http://otherhost:9200&quot;,
      "username": "user",
      "password": "pass"
    },
    "index": "source",
    "query": {
      "match": {
        "test": "data"
      }
    }
  },
  "dest": {
    "index": "dest"
  }
}
```
# 2、es迁移工具：elasticsearch-migration
6.0的已经支持，https://github.com/medcl/esm/releases/tag/v0.4.1

# 3、如何将多个token 合并成一个 token
请问  如何将字符串 "bags and shoes" 分析成 "bag and shoe" 
 
例如： 
  1. 有字符串"bags and shoes", 应用Standard Tokenizer，得到分词结果 "bags"  "and"  "shoes"  (3个token) 
  2. "bags"  "and"  "shoes" 应用 Porter Stem Token Filter，
     得到分词结果："bag"  "and"  "shoe"  (3个token) 
  3. 有没有合适的token filter 类型，能够将 "bag"  "and"  "shoe" 合并成单个token： "bag and shoe" ？ 
     或者其他的方法，将"bags and shoes" 分析为  "bag and shoe"  （keyword类型，或者单个token的text类型)
     
 【回答】用 phrase 查询不就好了，为什么一定要拼在一起呢？
 
如果只是上面的命题，也有办法，假设固定是 3 个 token，用 shingle filter:

```
DELETE index

PUT index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "myanalyzer": {
          "type": "custom",
          "tokenizer": "letter",
          "filter": [
            "stemmer",
            "myfilter"
          ]
        }
      },
      "filter": {
        "myfilter": {
          "type": "shingle",
          "min_shingle_size": 3,
          "max_shingle_size": 10,
          "output_unigrams": false
        }
      }
    }
  }
}

GET index/_analyze
{
  "text": ["bags and shoes"], 
  "analyzer": "myanalyzer"
}
```

结果
```
{
  "tokens": [
    {
      "token": "bag and shoe",
      "start_offset": 0,
      "end_offset": 14,
      "type": "shingle",
      "position": 0
    }
  ]
}
```

# 4、discovery.zen.minimum_master_nodes 不生效怎么办

回复：
一个集群只能有一个 master！这个参数是说，必须有这么多可被评选的后续节点在集群中待命的意思，不是同时存在多个 master。
会干架的。

# 5、logstash能动态添加导入的表吗

现在有个需求: mysql隔一段时间就会增加一些表, 能不能在logstash运行的时候动态添加表,然后自动导入到elasticsearch里

【回复】
1.手动方式，Logstash 可以动态加载配置，远程修改配置可以自动更新。

2.可以通过通过读取 MySQL 元数据表来获取所有库表结果，自己在 Logstash 里面进行比较。然后动态修改 Logstash 规则导入。（有点复杂，但是可行）
 
还是手动维护比较靠谱。

# 6、Elasticsearch查询时指定分词器

有三种方式可以指定查询分析器:
1. 在mapping里指定search_analyzer，例如
```
PUT my_index
{
  "mappings": {
    "doc": {
      "properties": {
        "uid": {
          "type": "keyword"
        },
        "name": {
          "type": "text",
          "analyzer": "english",
          "search_analyzer": "standard"
        }
      }
    }
  }
}
```
 
2.使用URL Search的时候，指定analyzer参数 ，文档参考: https://www.elastic.co/guide/e ... .html , 对应的python代码范例: 
>>> es.search(index="my_index", analyzer="standard", q='name:"mark AND johnson"')
要注意的是，这里的analyzer只能和q这个参数搭配使用。 你的代码报错，是因为用的body参数，这个参数是没有analyzer参数搭配的。

3.使用Request Body Search，文档参考: https://www.elastic.co/guide/e ... .html  ,对应的python代码范例:
>>> dsl='{"query": {"match": {"name": {"query": "mark","analyzer": "standard"}}}}'
>>> es.search(index="my_index", body=dsl)
注意这个时候，analyzer是写到dsl里面的match query。

# 7、单索引拆成多索引。性能问题猜想。不知道对不对。

我现在有一个索引，大概70w/s tps. 200个shard。这时机器资源利用率已经很高了。 
我现在想拆索引，大概几种方案。不知道理解得对不对。
1.直接拆分成2个索引。单索引还是200 shard。  整个集群吞吐量不会提升,甚至会下降。索引多了，shard变多了，合并shard的压力会变大。因为调度器需要merge更多的小段了,对io要求更高了。参数: index.merge.scheduler.max_thread_count
2.拆成2个索引，单索引100shard。这个时候集群吞吐量跟之前比会稍微好点。但是优点查询的时候，如果能指定索引，在不能使用routing的情况下，查询性能会更好点。基于这点，我可以将索引拆成更多个。查询耗资源少了，写入就能用更多的资源了。但是master管理的元数据会稍微增加点（可以忽略不计）

【回复1】
不知道集群有多少个节点，推荐的分片数是 节点数*(2~3)；
可以通过 reindex API 将数据进行拆分，然后测试一下拆分效果；
如果不影响集群正常运行的情况下（可以设置 reindex 的速度），推荐进行尝试，猜想不如实践一下

【回复2】
你的的猜想和我的理解基本上一致，不过还是对比测试一下再做结论。

# 8、profile参数查询耗时对不上

应该是并行的原因。
1、profile返回的是每个分片请求的时间，每个分片唯一id，举例：
"id": "[2aE02wS1R8q_QFnYu6vDVQ][twitter][0]
2、检索是针对一个或着多个索引的多个或N个分片执行的；
由于多个分片是并行操作的，所以单个分片的和不等于检索总时间。

# 9、float类型存储在es中会有精度损失

mapping中设置字段为fvalue：float。导入数据是用的1.01。结果查询出来的结果就变成了1.0099999904632568。请教一下，这种问题怎么解决。

【原因1】
嗯，_source直接是字符串的返回，输入的是什么就是什么。
我跟了一下代码，用的transport client。看到的结果是SearchHit返回结果中，**float对应的字符的值是double型**的。
然后我试了一下。
```
float fvalue = 1.01f;
BigDecimal bigDecimal = new BigDecimal(fvalue);
System.out.println(bigDecimal.doubleValue()); 输出的就是1.0099999904632568
```

【wood大叔验证】
你应该是从doc里读取的数据，如果从_source里读取就没这个问题。 
不太清楚doc_values为什么对float类型会有精度损失，
不过测试了一下，如果用double，则doc value里读取出来的精度和source里的一样，没有这个问题。
```
PUT testme
{
  "settings": {},
  "mappings": {
    "doc": {
      "properties": {
        "id": {
          "type": "double"
        }
      }
    }
  }
}

POST testme/doc
{
  "id": 1.01
}

POST testme/_search
{
  "docvalue_fields": [
    "id"
  ]
}

{
  "took": 0,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 1,
    "hits": [
      {
        "_index": "testme",
        "_type": "doc",
        "_id": "eKQxamUBsQ3QCcRZRbR5",
        "_score": 1,
        "_source": {
          "id": 1.01
        },
        "fields": {
          "id": [
            1.01
          ]
        }
      }
    ]
  }
}
```
 
 
或者觉得doulbe精度过高，浪费存储空间的话，也可以用**scaled_float**，看起来也是OK的
```
PUT testme
{
  "settings": {},
  "mappings": {
    "doc": {
      "properties": {
        "id": {
          "type": "scaled_float",
          "scaling_factor": 100
        }
      }
    }
  }
}

POST testme/doc
{
  "id": 1.01
}

POST testme/_search
{
  "docvalue_fields": [
    "id"
  ]
}

{
  "took": 0,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 1,
    "hits": [
      {
        "_index": "testme",
        "_type": "doc",
        "_id": "R6QwamUBsQ3QCcRZyrQK",
        "_score": 1,
        "_source": {
          "id": 1.01
        },
        "fields": {
          "id": [
            1.01
          ]
        }
      }
    ]
  }
}
```

# 10、在Elasticsearch 6.1.3版本中，发现translog文件过多导致异常


我们在压力测试中，通过压力测试，发现translog文件过多，导致OS句柄消耗完毕。

搜了社区问题，和这个很类似：https://elasticsearch.cn/question/1343。
但我们当前版本已经是6.1.3了，难道在这个版本还存在类似问题？或者是某个地方没配置好？

在指定index的某个shard下，translog文件个数超过13万。
此index的setting信息如下：
```
 curl -XGET -k -u : "http://127.0.0.1:9200/myindex- ... ot%3B
{
  "myindex-002" : {
    "settings" : {
      "index" : {
        "refresh_interval" : "30s",
        "number_of_shards" : "60",
        "provided_name" : "myindex-002",
        "creation_date" : "1526301558029",
        "number_of_replicas" : "0",
        "uuid" : "iM0QsRb3SXuDpz6ZbBi-wg",
        "version" : {
          "created" : "6010399"
        }
      }
    }
  }
}
```

我感觉这个bug和6.x引入的translog retention策略有关系。  
 
为了加速热索引的recovery， 6.x开始对于translog不再是flush以后立即清除，而是保留一定的大小，由以下两个参数控制：

index.translog.retention.size    #默认512mb
index.translog.retention.age    #默认12h

 
保留一定量的translog的目的，是为了出现热索引recovery情况的时候，借助保留的translog和seqno (也是6.x引入的，记录已经提交到lucene的文档序列号)， 可以免去跨结点的shard文件拷贝消耗，直接从translog快速恢复数据。
 
由于保留了一定时间的translog不清除，那么判断是否需要flush，以及flush的时候清除哪些文件的的条件就复杂了一些。需要比较哪些translog里的doc已经全部提交，哪些还未提交或者部分提交。 这些判断是通过比较translog里保留的seqno和local checkpoint记录的seqno来做出的。
 
但是这个特性实现上看起来有些bug，在一些极端场景造成了flush死循环。 官方尝试在6.1.3/6.2.0修复这个问题( pull/28350 )， 但问题并未真正解决。  
 
在用户报告问题以后，官方又发布了6.2.4 (pull/29125)， 经过我们生产集群的验证，升级到6.2.4以后再未遇到类似的问题。

# 11、wildcard性能

【wood】将该字段类型设置为keyword就可以满足你的要求，只是这种前缀通配符查询效率不高，在数据量很大的情况下可能会非常慢。

# 12、【好问题】发起
ESdata节点脱离集群，系统日志报120秒超时

赞，信息给的挺丰富，这个值得大家学习！说一下我能看到的问题：
1）GC 挺严重的， 这个会耗 cpu，建议调一下 young 的 heap 大小，或者直接上 G1 试一下
-XX:+UseG1GC
-XX:MaxGCPauseMillis=50
2）日志类的 Shard 大小不必严格按照30GB 来规划，可以增大，比如到50GB，再结合你一共12个节点，这样你就用120个 shard，这样每台机器10个 shard，方便均匀分配
 
3）force merge 先停掉，这个比较耗 cpu
 
修改配置再观察下看

# 13、doc_values禁用索引大小不减反增

你看的索引变大是怎么看的？如果是看磁盘里面文件夹的大小，那么6.3版本的话要考虑 translog 的大小

# 14、日志过长(whose UTF8 encoding is longer than the max length 32766)无法导入es

1、ES5.X版本以后，keyword支持的最大长度为32766个UTF-8字符，也就是说term精确匹配的最大支持的长度为32766个UTF-8个字符。
2、设置ignore_above后，超过给定长度后的数据将不被索引，无法通过term精确匹配检索返回结果。
3、​text对字符长度没有限制。
这是做过的验证：https://blog.csdn.net/laoyang3 ... 07980
参考一下。

# 15、es搜索超时

这个需要分析下查询耗时高的时间点段，查询量是否增大，seach队列是否有堆积，es是否发生gc，ioutil是否100%这些方面进行排查。

# 16、Rally一台机器上能否运行多实例

一台机器上只能起跑一个rally压测，因为rally运行前会判断是否有rally进程存在，如果存在当前rally就运行失败。
 
可以分布式压测
1.选择一台作为coordinator
esrallyd start --node-ip=x.x.x.x --coordinator-ip=x.x.x.x
 
2.在其他节点上运行
esrallyd start --node-ip=x.x.x.x --coordinator-ip=x.x.x.x
esrallyd start --node-ip=x.x.x.x --coordinator-ip=x.x.x.x
 
3.执行压测时增加参数 --load-driver-hosts
esrally race --pipeline=benchmark-only --load-driver-hosts=x.x.x.x,x.x.x.x,x.x.x.x  --target-hosts=x.x.x.x:9200 --track=ustest --challenge=append-no-conflicts --distribution-version=2.3.3 --offline
 
可以参考官网https://esrally.readthedocs.io ... river

rally并发不是用线程模型，而是基于actor模型的库，rally作为压测客户端一般不会是瓶颈。
你可以监控下rally所在节点负载网络情况。如果某个吞吐量指标不再提高，扩个rally压测节点后吞吐量上去了，那就能确定单节点rally能提供多大的压力了。

# 17、ES 父文档聚合子文档?

查询父文档中field为value的个数，同时返回子文档内容
{
  "size":10,
  "query":{
    "has_child":{
      "type":"child_type_name",
      "query":{
        "term":{
          "field":{
            "value":"value"
          }
        }
      },
      "inner_hits":{}
    }
  }
}
查询子文档中field为value的个数，同时返回父文档内容
{
  "size":10,
  "query":{
    "has_parent":{
      "type":"parent_type_name",
      "query":{
        "term":{
          "field":{
            "value":"value"
          }
        }
      },
      "inner_hits":{}
    }
  }
}

# 18、elasticsearch 每个shard对应的文件含义
lucene文件结构：https://www.elastic.co/blog/found-dive-into-elasticsearch-storage#lucene-index-files
ES存储详解：https://www.elastic.co/blog/found-dive-into-elasticsearch-storage#lucene-index-files

# 19、logstash同步MySQL的原理是什么？

Logstash 的 jdbc 插件可以实现数据的同步，默认是通过 sql 语句查询来实现的，结合定时器实现数据的同步；
 
想实现数据修改后能够同步，推荐在设计数据库表的时候添加修改日期字段，logstash 的同步 sql 结合 sql_last_value 可以根据更新时间实现增量更新。
 
由于同步是根据查询结果进行的，所以同步过程可以修改 mysql。

# 29、es的客户端负载平衡？es的Java客户端会负载平衡吗，es和spark的接口会自动负载平衡吗？

1.  ES 的客户端默认会自动负载均衡；
2.  ES 和 Spark 的接口同样支持自动负载均衡，而且在设置的时候只需要设置一个节点 IP 即可，程序会自动发现其他可用节点。

——铭毅天下 公众号整理
Elasticsearch 基础、进阶、实战第一公众号！


